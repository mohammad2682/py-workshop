{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37502fdf-1573-45ee-8344-652fd851dd22",
   "metadata": {},
   "source": [
    "# __Python and Datascience Workshop__\n",
    "Author: Mohammad Akradi <sup>1</sup> <br>\n",
    "<sup>1</sup> Institute of Medical Science and Technology, Shahid Beheshti University, Tehran, Iran\n",
    "\n",
    "## __Session 2b__\n",
    "Now, it's time taht we go through pandas library to learn deal with tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d51335c-551a-43df-8369-eb41be2852fb",
   "metadata": {},
   "source": [
    "--- \n",
    "## 1. Pandas and Dataframe\n",
    "pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language. it can be easily installed using pip.\n",
    "\n",
    "A DataFrame is a data structure that organizes data into a 2-dimensional table of rows and columns, much like a spreadsheet. DataFrames are one of the most common data structures used in modern data analytics because they are a flexible and intuitive way of storing and working with data.\n",
    "<br>\n",
    "in a dataframe, each column shows a feature or label and each row represents a sample. it's template is like below table:\n",
    "\n",
    "| sample-id | feature_1 | ... | feature_n | label |\n",
    "| --------- | --------- | --- | --------- | ----- |\n",
    "| id_1      | value_11   | ... | value_n1   | classA|\n",
    "| id_2      | value_12   | ... | value_n2   | classB|\n",
    "| ...     | ...   | ... | ...   | ...|\n",
    "| id_m      | value_1m   | ... | value_nm   | classA|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f091757-8fe9-4efe-9a38-ac3b83a54580",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Creating Dataframe\n",
    "There are lots of ways to create a dataframe with pandas. we've showed some methods in the example below:\n",
    "\n",
    "* Example #1:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# creating an empty dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# creating a dataframe from a list of values with arbitrary colnames:\n",
    "lst = [[\"sub1\", 20], [\"sub2\", 22], [\"sub3\", 24]]\n",
    "pd.DataFrame(lst, columns = [\"sub-id\", \"age\"])\n",
    "\n",
    "# creating a dataframe using a dictionary:\n",
    "dct = {\"sub-id\": [\"sub1\", \"sub2\", \"sub3\"], \"age\": [20, 22, 21]}\n",
    "pd.DataFrame(dct)\n",
    "\n",
    "# creating a dataframe using a dictionary with arbitrary colnames and index:\n",
    "lst = [[\"sub1\", 20], [\"sub2\", 22], [\"sub3\", 24]]\n",
    "pd.DataFrame(lst, columns = [\"sub-id\", \"age\"], index = [\"gold\", \"silver\", \"bronze\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96404c9-0d48-410d-9bdc-90e5d93eeb59",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Load and Save Data\n",
    "know, we will load a data from seaborn module.\n",
    "\n",
    "* Example #1:\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "iris.head()\n",
    "```\n",
    "\n",
    "however, if we have data file on our device, we can load it with pandas library:\n",
    "\n",
    "* Example #2:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "iris = pd.read_csv(\"Materials/iris.csv\")\n",
    "iris.head()\n",
    "```\n",
    "\n",
    "if we want to save `iris` dataframe, we use `pd.to_csv` function:\n",
    "\n",
    "* Example #3:\n",
    "\n",
    "```python\n",
    "# save file in the current directory\n",
    "iris.to_csv(\"iris.csv\")\n",
    "\n",
    "# save file in other directory\n",
    "iris.to_csv(\"<directory_path>/iris.csv\")\n",
    "```\n",
    "\n",
    "in a dataframe, some columns may be categorical, which have more than one value, but repeated; we call its values as their level:\n",
    "\n",
    "* Example #4:\n",
    "\n",
    "```python\n",
    "# to select a column from dataframe:\n",
    "iris['species']\n",
    "\n",
    "# or\n",
    "iris.species\n",
    "\n",
    "# for displaying a categorical column's different levels:\n",
    "print(iris['species'].unique())\n",
    "```\n",
    "\n",
    "if we want to make a copy from dataframe, we use `df.copy()` function:\n",
    "\n",
    "* Example #5:\n",
    "\n",
    "```python\n",
    "df = iris.copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2a5207-b203-4b54-801f-0b74949255ed",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Delete data from a dataframe\n",
    "to drop a column from dataframe we use `df.drop` function:\n",
    "\n",
    "* Example #4:\n",
    "\n",
    "```python\n",
    "iris.drop(columns = \"sepal_length\")\n",
    "\n",
    "# if we want to drop more than one column, we should put col-names in the []\n",
    "\n",
    "iris.drop(columns = [\"sepal_length\", \"sepal_width\"])\n",
    "\n",
    "# to save changes in the dataframe we set inplace arguman value to True\n",
    "iris.drop(columns = \"sepal_length\", inplace = True)\n",
    "```\n",
    "\n",
    "if we want to drop a row from dataframe, again we use `drop` function:\n",
    "\n",
    "* Example #5:\n",
    "\n",
    "```python\n",
    "'''\n",
    "labels : single label or list-like\n",
    "    Index or column labels to drop.\n",
    "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
    "    Whether to drop labels from the index (0 or 'index') or\n",
    "    columns (1 or 'columns').\n",
    "index : single label or list-like\n",
    "    Alternative to specifying axis (``labels, axis=0``\n",
    "    is equivalent to ``index=labels``).\n",
    "columns : single label or list-like\n",
    "    Alternative to specifying axis (``labels, axis=1``\n",
    "    is equivalent to ``columns=labels``).\n",
    "'''\n",
    "\n",
    "iris.drop(label=2, axis=0) \n",
    "# or\n",
    "iris.drop(label=2, axis='index')\n",
    "\n",
    "iris.drop(index=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23181a-c1ba-4062-8b54-ddbab6264e12",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Update data in a dataframe\n",
    "\n",
    "we can select a column by its name in `[ ]` or after \".\". for example, if we want to choose column \"sepal_length\" from iris dataset, we write `iris['sepal_length']` or `iris.sepal_length`. <br>\n",
    "for selecting a row, we can use both `loc` or `iloc` functions.\n",
    "\n",
    "* Example #1:\n",
    "\n",
    "```python\n",
    "sepal_length = iris['sepal_length']\n",
    "\n",
    "# or\n",
    "sepal_length = iris.filter(items=[\"sepal_length\"])\n",
    "\n",
    "print(sepal_length)\n",
    "\n",
    "first_row = iris.loc[0]\n",
    "\n",
    "# If you want to see a selected row of a data frame as a data frame, you must put the row index in an additional []\n",
    "first_row = iris.loc[[0]]\n",
    "\n",
    "first_row = iris.iloc[[0]]\n",
    "```\n",
    "\n",
    "there is some differences between `loc` and `iloc`.\n",
    "\n",
    "* Example #2:\n",
    "\n",
    "```python\n",
    "iris.set_index('sepal_length', inplace=True)\n",
    "\n",
    "iris.loc[[5.1]]\n",
    "\n",
    "iris.iloc[[1]]\n",
    "```\n",
    "\n",
    "if we want to have a look at a specific column from a row, we can put the column name in `loc` function, however, in `iloc` function we should put the column's location\n",
    "\n",
    "* Example #3:\n",
    "\n",
    "```python\n",
    "iris.reset_index(inplace=True)\n",
    "\n",
    "iris.loc[[1], \"sepal_width\"]\n",
    "\n",
    "iris.iloc[[1], 2]\n",
    "\n",
    "# if we want to use iloc, it is very difficult to find location of a column in a dataframe with lots of columns\n",
    "iris.iloc[[1], iris.columns.get_loc(\"sepal_width\")]\n",
    "```\n",
    "\n",
    "Now that we have learned how to access a value from a specific sample in a dataframe, we can easily update the data.\n",
    "\n",
    "* Example #4:\n",
    "\n",
    "```python\n",
    "print(iris.loc[[10], \"sepal_length\"])\n",
    "iris.loc[[10], \"sepal_length\"] = 2\n",
    "print(iris.loc[[10, \"sepal_length\"]])\n",
    "```\n",
    "\n",
    "in the last example, we want to select samples with `sepal_length==5.1` and update their sepal_length data with 5.11.\n",
    "\n",
    "* Example #5:\n",
    "\n",
    "```python\n",
    "iris[\"sepal_length\"][iris[\"sepal_length\"]==5.1] = 5.11\n",
    "\n",
    "# we can do it with \"loc\"\n",
    "iris.loc[iris.sepal_length==5.1, \"sepal_length\"] = 5.11\n",
    "\n",
    "iris\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b8bb3-aebb-42aa-8d71-97507a75b5a0",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Missing values\n",
    "__First Look at the Dataset__\n",
    "\n",
    "* Example #1:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "iris_missing = pd.read_csv(\"Materials/iris-miss.csv\")\n",
    "iris_missing.head()\n",
    "\n",
    "iris_missing.info()\n",
    "\n",
    "# counting missing values\n",
    "print(iris_missing.isnull().sum())\n",
    "```\n",
    "\n",
    "* __Deleting columns with missing data__\n",
    "\n",
    "we can delete columns which have missing values\n",
    "\n",
    "* Example #2:\n",
    "\n",
    "```python\n",
    "iris_updated = iris_missing.dropna(axis = 1)\n",
    "\n",
    "# we can set a threshold for dropping columns:\n",
    "iris_updated = iris_missing.dropna(thresh = 150-10, axis = 1)\n",
    "```\n",
    "\n",
    "* __Deleting rows with missing data__\n",
    "\n",
    "another approach is to delete samples with missing values, again we can use threshold settings:\n",
    "\n",
    "* Example #3:\n",
    "\n",
    "```python\n",
    "iris_updated = iris_missing.dropna(axis = 0)\n",
    "\n",
    "# we can set a threshold for dropping columns:\n",
    "iris_updated = iris_missing.dropna(thresh = 4, axis = 0)\n",
    "```\n",
    "\n",
    "* __Filling the missing values (Imputation)__\n",
    "\n",
    "In this case, we will be filling the missing values with a certain number.\n",
    "\n",
    "The possible ways to do this are:\n",
    "\n",
    "1. Filling the missing data with the mean or median value if it’s a numerical variable.\n",
    "2. Filling the missing data with mode if it’s a categorical value.\n",
    "3. Filling the numerical value with 0 or -999, or some other number that will not occur in the data. This can be done so that the machine can recognize that the data is not real or is different.\n",
    "4. Filling the categorical value with a new type for the missing values.\n",
    "\n",
    "You can use the `fillna()` function to fill the null values in the dataset.\n",
    "\n",
    "* Example #4:\n",
    "\n",
    "```python\n",
    "iris_updated = iris_missing.copy()\n",
    "iris_updated[\"petal_length\"] = iris_updated[\"petal_length\"].fillna(iris_updated[\"petal_length\"].mean())\n",
    "\n",
    "iris_updated\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18872408-a217-4db3-a671-05c1c2ebf49b",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Replace\n",
    "sometimes we need to replace values in a column with new values. in this case, we use `replace` function. in this function the input is a dictionary in which the keywords are old values and values are the new values.\n",
    "\n",
    "* Example #1:\n",
    "\n",
    "```python\n",
    "print(iris[\"species\"].unique())\n",
    "\n",
    "iris_missing[\"species\"].replace({'setosa': 0, 'versicolor': 1, 'virginica': 2}, inplace=True)\n",
    "print(iris[\"species\"].unique())\n",
    "```\n",
    "\n",
    "another way to replace values in a columns, is to use `loc`.\n",
    "\n",
    "* Example #2:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "iris.loc[iris[\"petal_length\"]>iris[\"petal_length\"].mean(), \"petal_length\"] = np.nan\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d36507c-7b59-4bea-a2b9-e9eb37cc0199",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Grouping and Summarizing data\n",
    "In real data science projects, you’ll be dealing with large amounts of data and trying things over and over, so for efficiency, we use `Groupby` concept. Groupby concept is really important because it’s ability to aggregate data efficiently, both in performance and the amount code is magnificent.\n",
    "\n",
    "* Example #1:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "iris = pd.read_csv(\"Materials/iris.csv\")\n",
    "\n",
    "iris.groupby(by=\"species\").mean()\n",
    "\n",
    "# to add more functions we use \"agg\"\n",
    "iris.groupby(by=\"species\").agg([\"mean\", \"std\", \"median\"])\n",
    "\n",
    "# if we want to look at specific features:\n",
    "iris[[\"sepal_length\", \"sepal_width\", \"species\"]].groupby(by=\"species\").agg([\"mean\", \"std\", \"median\"])\n",
    "```\n",
    "\n",
    "other way to summarize data is using `describe` function. this function gives some basic information for each feature of dataframe. also, sometimes we need to count number of an specific value in a column. in this case, we use `value_counts` function.\n",
    "\n",
    "* Example #2:\n",
    "\n",
    "```python\n",
    "iris.describe()\n",
    "\n",
    "# describe specific columns\n",
    "iris[[\"sepal_length\", \"sepal_width\"]].describe()\n",
    "\n",
    "# value_counts\n",
    "iris[\"species\"].value_counts()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0111d1-2b4f-40fb-b493-49f0d0b47027",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Merge and Concatenate\n",
    "in some cases, we have two or more seprated dataframes that we want to merge them together. so we use one of the `merge` or `concat` functions. firstly, we create 3 dataframes and concat them:\n",
    "\n",
    "* Example #1:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
    "    },\n",
    "    index=[0, 1, 2, 3],\n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n",
    "        \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n",
    "        \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n",
    "        \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n",
    "    },\n",
    "    index=[4, 5, 6, 7],\n",
    ")\n",
    "\n",
    "df3 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"A8\", \"A9\", \"A10\", \"A11\"],\n",
    "        \"B\": [\"B8\", \"B9\", \"B10\", \"B11\"],\n",
    "        \"C\": [\"C8\", \"C9\", \"C10\", \"C11\"],\n",
    "        \"D\": [\"D8\", \"D9\", \"D10\", \"D11\"],\n",
    "    },\n",
    "    index=[8, 9, 10, 11],\n",
    ")\n",
    "\n",
    "frames = [df1, df2, df3]\n",
    "df = pd.concat(frames, axis=0, join=\"outer\")\n",
    "```\n",
    "\n",
    "Suppose we wanted to associate specific keys with each of the pieces of the chopped up DataFrame. We can do this using the keys argument:\n",
    "\n",
    "* Example #2:\n",
    "\n",
    "```python\n",
    "result = pd.concat(frames, keys=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "result.loc[\"y\"]\n",
    "```\n",
    "\n",
    "if we set `join` arguman to `inner` and `axis` to 1, then rows with same indexes will be concat together:\n",
    "\n",
    "* Example #3:\n",
    "\n",
    "```python\n",
    "df4 = pd.DataFrame(\n",
    "    {\n",
    "        \"B\": [\"B2\", \"B3\", \"B6\", \"B7\"],\n",
    "        \"D\": [\"D2\", \"D3\", \"D6\", \"D7\"],\n",
    "        \"F\": [\"F2\", \"F3\", \"F6\", \"F7\"],\n",
    "    },\n",
    "    index=[2, 3, 6, 7],\n",
    ")\n",
    "\n",
    "result = pd.concat([df1, df4], axis=1)\n",
    "result\n",
    "\n",
    "# inner join:\n",
    "result = pd.concat([df1, df4], axis=1, join=\"inner\")\n",
    "result\n",
    "```\n",
    "\n",
    "pandas provides a single function, `merge()`, as the entry point for all standard database join operations between DataFrame or named Series objects:\n",
    "\n",
    "* Example #4:\n",
    "\n",
    "```python\n",
    "df_left = pd.DataFrame(\n",
    "    {\n",
    "        \"key\": [\"K0\", \"K1\", \"K2\", \"K3\"],\n",
    "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "df_right = pd.DataFrame(\n",
    "    {\n",
    "        \"key\": [\"K0\", \"K1\", \"K2\", \"K3\"],\n",
    "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "df_left.merge(df_right, on = \"key\") # there are more options like {left_on, right_on, how, ...}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
